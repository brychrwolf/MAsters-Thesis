\newglossaryentry{sector}{
	name=sector,
	description={or ``circle sector''; the minor sector of a circle defined by its radius and central angle},
	plural=sectors
}

\newglossaryentry{bisectingLine}{
	name=bisecting line,
	description={the line which bisects the central angle of a circle sector}
}

\newglossaryentry{mutex}{
	name=mutex,
	description={an abbreviation for ``mutual exclusion'', a locking mechanism which allows only one single threads to enter a critical section of code at a time},
	symbol={\ensuremath{\mu}}
}

\newglossaryentry{criticalSection}{
	name=critical section,
	description={sections of code containing the instructions that read from or write to volatile memory}
}

\newglossaryentry{programCorrectness}{
	name=program correctness,
	description={defined by the field of theoretical computer science as existing only when, for each input given, a program produces the expected output}
}

\newglossaryentry{volatileMemory}{
	name=volatile memory,
	description={memory that may be changed by any thread, especially during parallel processing, requiring thread synchronization before access to ensure program correctness}
}

\newglossaryentry{mutableMemory}{
	name=mutable memory,
	description={memory that may be changed by a specific thread, especially during parallel processing, not requiring a mutex}
}

\newglossaryentry{principleLoop}{
	name=principle loop,
	description={the loop for convolving \Fors{t}}
}

\newglossaryentry{efficiency}{
	name=efficiency,
	description={in regards to parallel processing, efficiency is the ratio of the speedup obtained by a parallel algorithm, divided by the count of processors used to obtain the parallel compute time. It will always be less than or equal to one, and represents the share of the maximal achieveable speedup obtained by the algorithm}
}

\newglossaryentry{speedup}{
	name=speedup,
	description={in regards to a parallel algorithm, speedup is the ratio of the compute time requried for the optimal serial algorithm to run, divided by the compute time required by the parallel algorithm. Speedup will always be less than the number of processors used. Also, as the goal of a parallel algorithm is to complete work faster than its serial variant, it is good for speedup to be a number much greater than one}
}

\newglossaryentry{degreeOfPar}{
	name=degree of parallelism,
	description={which is the maximum number of operations in an algorithm, which can be executed in parallel}
}

\newglossaryentry{stride}{
	name=stride,
	description={the size of a block of work intended for a single processor, equal to the problem size divided by the number of available processors},
	symbol={\ensuremath{\sigma}}
}

\newglossaryentry{ddf}{
	name=Dirac delta function,
	description={when applied as a scalar field, a function value of one at the center point, and zero everywhere else}
}

\newglossaryentry{acquiredTDD}{
	name=acquired \tdd{},
	description={}
}

\newglossaryentry{syntheticTDD}{
	name=synthetic \tdd{},
	description={}
}

\newglossaryentry{Amdahl}{
	name=Amdahl's law,
	description={Given a constant problem size, the limit as the count of processors goes to infinity, the speedup obtained will only approach the inverse of the degree of parallelism exhibited by the algorithm, a problem which can be partially mitagated by only increasing the number of processors in realtion to the size of the problem}
}

\newglossaryentry{lawOfSines}{
	name=law of sines,
	description={}
}


\newglossaryentry{lawOfCosines}{
	name=law of cosines,
	description={}
}



\newacronym{CPU}{CPU}{Central Processing Unit}
\newacronym{GPU}{GPU}{Graphics Processing Unit}
\newacronym{GPGPU}{GPGPU}{General Purpose, Graphics Processing Unit}
\newacronym{CUDA}{CUDA}{Compute Unified Device Architecture}
\newacronym{PNG}{PNG}{Portable Network Graphic}
\newacronym{MSII}{MSII}{the Multi-Scale Integral Invariants filter}
\newacronym{ILATO}{ILATO}{Improving Limited Angle computed Tomography by Optical data integration}
\newacronym{SIMD}{SIMD}{Single Instruction, Multiple Data}
