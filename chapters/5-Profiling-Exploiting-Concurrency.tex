\chapter{Profiling \& Exploiting Concurrency}
\label{ch5}
In the previous chapter we presented an improved version of \Forf{t} as it is currently implemented within the GigaMesh framework, and while it has improved accuracy in regards to the weights, it is still yet entirely serial in design, so that unfortunately, its performance suffers greatly under the complexity of modern mesh sizes, which with the current high resolution scanners in use, can grow to be MESH\_SIZES\todoResearch{mesh sizes}. We will now explore this as-yet-unpublished algorithm in order to negotiate any instances of control or data dependency, and hopefully discover opportunities worthy of exploiting concurrency in order to improve its performance when implemented on a system capable of parallel computation.

%
%
%
%
\section{The Serial Algorithm}
\label{ch5sSI}
In this section, we now combine all of the equations from the previous chapter,~\ref{eq:localMinimumEdgeLength} through~\ref{eq:meanFuncValAtPv}, into a three-part algorithm using mathematical pseudo-code, with the goal of facilitating the implementation of the improved version of \forf{t}. To that end, before one is able to actually begin convolving the filter, the computations require that the one-ring neighborhoods already be known. Also, during the convolutions, the filter uses all edge lengths at least once per iteration, and twice for non-border edge lengths, which are shared between adjacent neighborhoods. Therefore, it is beneficial to split the algorithm into three distinct parts, then save the results of the first two parts to be used during the iterative convolutions of the third part, with the result being a massive increase in efficiency by greatly reducing the number of operations-per-iteration required.
\todoBackground{add convolution and convolve to background}
\todoBackground{memory vs speed cost compromise}

%
%
\subsection{Discovering Neighborhoods}
\label{ch5sSIssDN}
Initially, one must discover all the points $\bp_i$ which comprise each neighborhood $\bN_v$ in the entire mesh $\bM$, which is the purpose of Algorithm~\ref{alg:serialBuildNeighborhoods}. Although building this family of sets outside of the principle loop adds an additional $2\cdot |\bT|^3$ operations in total, doing so enables Alogrithm~\ref{alg:serialCalculateEdgeLengths} to exploit this family of sets to vastly reduce its complexity from $|\bP|^{|\bT|}$ to approximately\footnote{depending on the average size of all neighborhoods, assumed here to be about 6}\todoResearch{find good average for average neighborhood size} $|\bP|^6$. Also, as we will see in Algorithm~\ref{alg:serialConvolveFilter}, when $\tau$ is the chosen number of iterations to perform, the complexity of the main procedure can be meaningfully reduced to only $\tau^{|\bP|^{6*3}}$, down from the $\tau^{|\bP|^{(|\bF|*3)}}$ that would have been necessary had the neighborhoods not already been discovered and the procedure been otherwise required to discover the members of $\bN_v$ in each iteration.%
\nomenclature[na]{$\tau$}{the chosen number of iterations to perform}%
\todoBackground{complexity, big O notation}

Figure~\ref{fig:serialBuildNeighborhoods} describes a very simple mesh consisting of just four points and two faces, similar to what is seen in Figure~\ref{fig:triangularFaces}. The two faces, $\bt_1$ and $\bt_2$, are colored in sand and coral color respectively. The arrows represent the union operation of a point and a neighborhood, and are colored to match the face from where the point had come. The two pairs of arrows pointing from $\bp_2$ to $\bN_3$ and $\bp_3$ to $\bN_2$ are specifically colored teal to highlight the fact that these union operations occur twice, originating one each from each of the faces, but because of the uniqueness property of a set, the duplicated operations are wholly inconsequential to the the final membership of either neighborhood. Also notice that for every face which contains its center point, the union operation is called twice on neighborhood. This realization will eventually influence the design of the parallel variant of the algorithm.

\tikzset{%
	>={Latex[width=2mm,length=2mm]},
	baseNode/.style = {rectangle, rounded corners,
		draw=black, fill=white, thick,
		minimum width=1cm, minimum height=1cm,
		text centered, font=\sffamily},
	baseLine/.style = {double, thick},
	tealStyle/.style = {draw=MyTeal, fill=MyLtTeal},
	coralStyle/.style = {draw=MyCoral, fill=MyLtCoral},
	sandStyle/.style = {draw=MySand, fill=MyLtSand},
	faceL/.style = {baseNode, sandStyle},
	lineL/.style = {baseLine, sandStyle},
	faceR/.style = {baseNode, coralStyle},
	lineR/.style = {baseLine, coralStyle},
	lineC/.style = {baseLine, tealStyle},
	point/.style = {baseNode},
	nbhd/.style = {baseNode, minimum width=2cm}
}
\begin{figure}[ht]
	\begin{tikzpicture}[node distance=0cm]
		\coordinate (center1) at (0cm,0cm);
		\node (t1) [faceL, anchor=east, xshift=-.5cm] {$\bt_1 = \{\bp_1,\,\bp_2,\,\bp_3\}$};
		\node (t2) [faceR, anchor=west, xshift= .5cm] {$\bt_2 = \{\bp_3,\,\bp_2,\,\bp_4\}$};
		\coordinate (center2) at (0cm,-1.5cm);
		\node (p1) [point, left of=center2, xshift=-3cm] {$\bp_1$};
		\node (p2) [point, left of=center2, xshift=-1cm] {$\bp_2$};
		\node (p3) [point, right of=center2, xshift=1cm] {$\bp_3$};
		\node (p4) [point, right of=center2, xshift=3cm] {$\bp_4$};
		\coordinate (center3) at (0cm,-4.5cm);
		\node (n1) [nbhd, left of=center3, xshift=-5cm] {$\bN_1$};
		\node (n2) [nbhd, left of=center3, xshift=-1.75cm] {$\bN_2$};
		\node (n3) [nbhd, right of=center3, xshift=1.75cm] {$\bN_3$};
		\node (n4) [nbhd, right of=center3, xshift=5cm] {$\bN_4$};

		\draw[-, lineL] (t1) -- (p1);
		\draw[-, lineL] (t1) -- (p2);
		\draw[-, lineL] (t1) -- (p3);

		\draw[->, lineL] (p1) -- (n2);
		\draw[->, lineL] (p1) -- (n3);
		\draw[->, lineL] (p2) -- (n1);
		\draw[->, lineC] (p2) -- (n3.180);
		\draw[->, lineL] (p3) -- (n1);
		\draw[->, lineC] (p3) -- (n2);

		\draw[-, lineR] (t2) -- (p2);
		\draw[-, lineR] (t2) -- (p3);
		\draw[-, lineR] (t2) -- (p4);

		\draw[->, lineC] (p3) -- (n2.0);
		\draw[->, lineR] (p3) -- (n4);
		\draw[->, lineR] (p2) -- (n4);
		\draw[->, lineC] (p2) -- (n3);
		\draw[->, lineR] (p4) -- (n3);
		\draw[->, lineR] (p4) -- (n2);
	\end{tikzpicture}
	{\caption[Serial Build Neighborhoods]{A very simple mesh consisting of just four points and two faces, similar to what is seen in Figure~\ref{fig:triangularFaces}. $\bt_1$ is in sand color, and $\bt_2$ is in coral color. The arrows represent the union operation of a point into a neighborhood, and are colored to match the face from where the point had come. The two pairs of arrows pointing from $\bp_2$ to $\bN_3$ and $\bp_3$ to $\bN_2$ are colored in teal to highlight the fact that these union operations occur twice.
}\label{fig:serialBuildNeighborhoods}}
\end{figure}

In Algorithm~\ref{alg:serialBuildNeighborhoods}, the function \textit{serialBuildNeighborhoods} describes iterating over every triangular face $\bt$ in $\bT$, then for each of the face's three corner points, union into its neighborhood the other two points which are adjacent to it. The result is a fully populated family of sets $\bN$, storing references to every neighbor of every neighborhood in the mesh.

\begin{algorithm}[ht]
	\DontPrintSemicolon
	\SetCommentSty{small}
	\SetKwFor{For}{for}{:}{}
	\SetKwProg{Func}{Function}{}{}
	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}

	\Input{the set of all triangular faces $\bT$}
	\Output{the family of sets of discovered neighborhoods $\bN$}

	\bigskip
\nl	\Func{serialBuildNeighborhoods($\bT$)}{\label{sbn1}
\nl		\For(\tcc*[f]{$\bt = \left \{\bp_a, \bp_b, \bp_c\right \}$}){$\bt \in \bT$}{\label{sbn2}
\nl			\ProgSty{union($\bN$, $\bp_a$, $\bp_b$, $\bp_c$)}\;\label{sbn3}
\nl			\ProgSty{union($\bN$, $\bp_b$, $\bp_a$, $\bp_c$)}\;\label{sbn4}
\nl			\ProgSty{union($\bN$, $\bp_c$, $\bp_a$, $\bp_b$)}\;\label{sbn5}
		}
	}

	\bigskip
\nl	\Func{union($\bN$, $a$, $b$, $c$)}{\label{sbn7}
\nl		$\bN_a \leftarrow \bN_a \cup \{b,\,c\}$\;\label{sbn8}
	}
	\caption{Serial algorithm for building the family of sets of all discovered members of each neighborhood in the mesh\label{alg:serialBuildNeighborhoods}}
\end{algorithm}%

The function ``union'' is separated here for two reasons: the first reason is that this way, it becomes very clear that the union operation behaves similarly for all three permutations\footnote{In general, a set of three numbers has six permutations, however, here only the first index is important, and the order of the second two parameters are arbitrary due to the commutative property of the union operation, resulting in only 3 distinct possibilities} of corners, and indeed it is only the order of the indices which changes; and the second reason is that this signature matches more closely that of the parallel version, Algorithm~\ref{alg:parallelBuildNeighborhoods}, which requires the union operation to remain separate.
\todoBackground{Commutative property of union operation}

%
%
\subsection{Calculating Edge Lengths}
\label{ch5sSIssCEL}
Having now built in the previous section the family of sets of neighborhoods $\bN$, we can advance to the next step, Algorithm~\ref{alg:parallelCalculateEdgeLengths}, which iterates over each pair of neighbors comprising $\bN$, with the goal of building a set of pre-calculated edge lengths $\bE$, as well as determining the global minimum edge length $\gelm$; both being essential parameters of Algorithm~\ref{alg:serialConvolveFilter}.

As shown in Equation~\ref{eq:defineEdgeLengthPoint}, the calculation of an edge's length requires taking the L2-norm of the difference between two points, which itself involves using the square root operation. In modern software, the square root operation is performed by computing ``Newton's Iteration'', or ``Newton's method''\todoCitation{software uses Newton's iteration for sqrt}, which is essentially multiple iterations of the so-called, ``recurrence equation''.~\cite{Weisstein19b}\todoCitation{Newton's iteration uses recurrence equation} The impact for \forf{t} is that the computation of a square root typically\todoReword{add footnote with desc and citation}\todoCitation{how slow is Newton's iteration compared to others} takes many more compute cycles than  any other binary or unary operation, thus taking more time to complete overall. In fact, because of the slowness of the square root operation, computing the L2-norm in order to calculate an edge's length is empirically the most costly operation performed by the filter\todoResearch{qualify, do experiment to prove how slow sqrt is, maybe make appendix entry about what it is and why it is so slow}. Therefore, it is imperative that we pay special attention to avoid unnecessary instructions to calculate an edge's length. For that reason, we define the symbol $\ellstar$ to represent the calculation of an edge's length using ``Newton's Iteration'', so as to draw focus to its importance while designing an efficient implementation of \forf{t}.%
\nomenclature[oa]{$\ellstar$}{the procedure of calculating an edge's length using ``Newton's Iteration'', the most costly operation in the Fast One-Ring filter, due to use of $\sqrt{(\cdot)}$}

\begin{algorithm}[ht]
	\DontPrintSemicolon
	\SetCommentSty{small}
	\SetKwFor{For}{for}{:}{}
	\SetKwProg{Func}{Function}{}{}
	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}

	\Input{the set of all points $\bP$, \\
		the family of sets of discovered neighborhoods $\bN$}
	\Output{the set of pre-calculated edge lengths $\bE$, \\
		the globally shortest edge length $\gelm$}

	\bigskip
	\Func{serialCalculateEdgeLengths($\bP$, $\bN$)}{
\nl		\For{$\bp_v \in \bP$}{\label{scel1}
\nl			\For{$\bp_i \in \bN_v$}{\label{scel2}
				\linespread{1.5}\selectfont
\nl				$\bE_{\sv{i}} \leftarrow |\bp_i - \bp_v|$\tcc*[r]{This is $\ellstar$ as in Eq:~\ref{eq:localMinimumEdgeLength}}\label{scel3}
\nl				$\gelm \leftarrow \min\left \{\gelm,\,\ell_{\sv{i}}\right \}$\tcc*[r]{Eq:~\ref{eq:globalMinimumEdgeLength}}\label{scel5}
			}
		}
	}
	\caption{Serial algorithm for calculating all the edge lengths between each pair of adjacent points in the mesh\label{alg:serialCalculateEdgeLengths}}
\end{algorithm}

Given the substantial impact of computing ${\ellstar}$ and the enormous number of times\todoReword{how many times} an edge length is required in the computation of the weighted mean function values per iteration of the filter on a mesh, pre-calculating the set all edge lengths outside of the principle loop becomes critical to the overall efficiency of the algorithm, despite the fact that it requires ${\ellstar}$ to be calculated and stored about $|\bP|^6$ times\footnote{depending on the average size of all neighborhoods, but assumed here to be about 6.}. It is of paramount importance for two reasons: the first reason is that without pre-calcuating each edge length, it would be otherwise impossible to calculate the global minimum  edge length $\gelm$, which is used in every iteration of the principle loop; and the second reason is that by recording the results of each edge length calculation in the set $\bE$, we are then able to completely exclude any further calculations of $\ellstar$ from the principle loop, and as can be seen in Algorithm~\ref{alg:serialConvolveFilter}, that reduces the total count of $\ellstar$ calculations performed by the filter down from the $(2\,\ell_{\sv{i}}^{\,border} + 4\,\ell_{\sv{i}}^{\,non-border})\cdot\tau^{|\bP|}$ had the procedure been required to calculate an edge length each time it was used during computation, to only the initial $1\cdot |\bP|^6$ pre-calculations; having become completely independent of $\tau$ and significantly more efficient overall.%
\nomenclature[ob]{$\bE$}{a set of pre-calculated edge lengths}%
\todoBackground{memory vs speed cost compromise}
\todoBackground{border vs non-border edge lengths}
\todoReword{three big paragraphs in a row is not pretty}

%
%
\subsection{Convolving the Filter}
\label{ch5sSIssCF}
In the third and final part, we present Algorithm~\ref{alg:serialConvolveFilter}, which describes the remaining steps required to convolve \Forf{t}. After having completed the discovery and pre-calculations of Algorithms~\ref{alg:serialBuildNeighborhoods} and~\ref{alg:serialCalculateEdgeLengths}, each convolution is performed for a user-defined number of iterations $\tau$, by convolving over each point $\bp_v$ in the set $\bP$. At each point, the neighboring points $\bp_i$ from set $\bN_v$ are then iterated over, in order to calculate each weighted mean function value $\check{f}$ at the center of gravity of the circle sector defined by $\bp_v$ and $\bp_i$. Next, the weighted mean $f'_v$ is evaluated with all the mean function values from the circle sectors comprising the geodesic disc centered on $\bp_v$,  and is then recorded in set $\bF'$, before \forf{t} finally moves to the next point in the mesh and its corresponding one-ring neighborhood.

\begin{algorithm}[ht]
	\DontPrintSemicolon
	\SetCommentSty{small}
	\SetKwFor{For}{for}{:}{}
	\SetKwProg{Func}{Function}{}{}
	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}

	\Input{the set of all points $\bP$, \\
		the family of sets of discovered neighborhoods $\bN$, \\
		the set of pre-calculated edge lengths $\bE$, \\
		the globally shortest edge length $\gelm$, \\
		the set of function values $\bF$, \\
		the chosen number of iterations $\tau$}
	\Output{the set of one-ring weighted mean function values $\bF'$}

	\bigskip
	\linespread{1}\selectfont
	\Func{convolveFilter($\bP$, $\bN$, $\bE$, $\gelm$, $\bF$, $\tau$)}{
\nl		\For{$\tau\leftarrow 1\;\KwTo\;\#iterations$}{
\nl			\For{$\bp_v \in \bP$}{
\nl				\For{$\bp_i \in \bN_v$}{
					\linespread{1.5}\selectfont
\nl					$\kern-0.5pt\alpha \leftarrow cos^{-1}$
					\begin{Large}
						$\kern-6pt\left (\frac{\bE_c^2\,+\,\bE_b^2\,-\,\bE_a^2}{2\,\cdot\,\bE_c\,\cdot\,\bE_b}\right )$\tcc*[r]{Eq:~\ref{eq:alphaFromEdgeLengths}}
					\end{Large}
					\linespread{1.2}\selectfont
\nl					$\kern0.00pt\beta \leftarrow (\pi - \alpha)\mathbin{/}2$\tcc*[r]{Eq:~\ref{eq:betaFromHalfAlpha}}
\nl					$\kern-1.5ptA \leftarrow \Big(\gelm\,\Big)^2\kern-4pt\cdot\alpha\mathbin{/}2$\tcc*[r]{Eq:~\ref{eq:circularSectorArea}}
\nl					$\kern1.00pt\check{\ell} \leftarrow \big(4\cdot\gelm\cdot\sin(\alpha\mathbin{/}2)\big)\mathbin{/}3\,\alpha$\tcc*[r]{Eq:~\ref{eq:distToCoG}}
\nl					$\kern1.00pt\zeta \leftarrow \gelm\mathbin{/}\sin(\beta)$\tcc*[r]{Eq:~\ref{eq:zeta}}
\nl					\For{$j \in {1,2}$}{
\nl						$\tilde{\ell}_j \leftarrow \zeta\mathbin{/}\bE_j$\tcc*[r]{Eq:~\ref{eq:distanceIForInterpolation},~\ref{eq:distanceIp1ForInterpolation}}
\nl						$f'_j \leftarrow f_0\cdot(1 - \tilde{\ell}_j) + f_j\cdot\tilde{\ell}_j$\tcc*[r]{Eq:~\ref{eq:interpolatedFi},~\ref{eq:interpolatedFip1}}
					}
\nl					$\check{f} \leftarrow f_0\cdot(1 - \check{\ell}) + \big((f'_1 + f'_2)\cdot\check{\ell}\big)\mathbin{/}2$\tcc*[r]{Eq:~\ref{eq:weightedMeanAtCoGatSector}}
\nl					$\kern-2.0pt\tilde{f}_v \leftarrow \tilde{f}_v + A\cdot\check{f}$\tcc*[r]{Eq:~\ref{eq:meanFuncValAtPv}}
\nl					$\kern-4.0pt\tilde{A}_v \leftarrow \tilde{A}_v + A$\tcc*[r]{Eq:~\ref{eq:meanFuncValAtPv}}
				}
\nl				$f'_v \leftarrow \tilde{f}_v\mathbin{/}\tilde{A}_v$\tcc*[r]{Eq:~\ref{eq:meanFuncValAtPv}}
			}
		}
\nl		$\bF' \leftarrow \left \{f'_1,\ldots,\,f'_{|\bP|}\right \}$\;
\nl 	$\bF \leftarrow \bF'$\tcc*{smooth newest values every iteration}
	}
	\caption{Serial algorithm for convolving \Forf{t}\label{alg:serialConvolveFilter}}
\end{algorithm}%
\nomenclature[pa]{$\tilde{f}$}{the total volume of function values over $\bO_v$}%
\nomenclature[pb]{$\tilde{A}$}{the area of $\bO_v$}%
\nomenclature[]{$\bF'$}{the set of one-ring weighted mean function values}%

While the performance of Algorithm~\ref{alg:serialConvolveFilter} is much improved with the pre-calculations performed in Algorithms~\ref{alg:serialBuildNeighborhoods} and~\ref{alg:serialCalculateEdgeLengths}, its strictly serial design prevents it from scaling in performance appropriately for the sizes of real-world, acquired \tdd{}, performing especially sluggishly for high numbers of iterations on meshes with large amounts of triangulated points\todoReference{a specific experiment} the very targets for which the filter is primarily intended.

In this section, we presented an improved version of \Forf{t}, as implemented within the GigaMesh framework. Unfortunately, it is still yet entirely serial in design, therefore, we will in the next section, endeavor to explore this as-yet-unpublished algorithm in order to discover possible occurrences of independent procedures worthy of exploiting with parallel processing, with the goal of improving the overall performance and scalability of \forf{t} when it is implemented on a system capable of parallel computation.


%
%
%
%
\section{The Parallel Algorithm}
\label{ch5sPA}
\todoBackground{Data dependencies}
Following the pattern set in Section~\ref{ch5sSI}, the parallel algorithm for \Forf{t} also has three main parts. In contrast however, the parallel variant of each of the three serial parts are split further into subroutines, in order to delegate blocks of instructions to separate threads of execution, while protecting critical sections, and avoiding data and control dependencies, so that the threads can be safely executed in parallel.

The following three sections will each focus on producing the parallel variant of one of the three parts of the serial algorithm, by first analyzing the serial algorithm through the lens of parallel programing, then defining the strategy behind the design of the parallel variant, then finally providing the pseudo code definitions to implement that part of the algorithm.

%
%
\subsection{Discovering Neighborhoods}
\label{ch5sPAssDN}
The sole purpose of Algorithm~\ref{alg:serialBuildNeighborhoods} is to generate a family of sets of neighborhoods $\bN$, by exploring every triangular face in the set, so that subsequent algorithms can recall and iterate over those associations without incurring the computational cost of searching the entire mesh each time. In addition to that goal, the parallel variant of the $\mathit{buildNeighborhoods}$ procedure should also provide a total count of all neighbors in all neighborhoods $\hat{n}$, so that the next two parts of the \forf{t} algorithm can predict and evenly delegate work loads to independent threads of execution.

In Algorithm~\ref{alg:serialBuildNeighborhoods}, line~\ref{sbn2}, the first line of the first function, we encounter a loop over each face $\bt$ in $\bT$. In general, concurrency found in the structure of a loop may be totally exploited by parallel systems, but only in the absence of loop-carried dependence. So, in order to determine if the iterations of the loop may be computed in parallel, an analysis of every operation in the loop block is required.\todoResearch{Amdahl's Law}\todoBackground{loop level parallelism, loop-carried and loop-independent}
\todoBackground{static vs volatile memory}

Figure~\ref{fig:paraBNDataDep} illustrates the data dependencies inherent to each iteration of the loop over the faces $\bt$ in $\bT$, as found from Algorithm~\ref{alg:serialBuildNeighborhoods}. First the triangular face $\bt$ is loaded, as denoted by the teal colored node, from the set $\bT$ in static memory which will never be modified by this, or any other procedure. Also, despite the fact that faces can be adjacent to one another, each face is distinctly defined in the set $\bT$, therefore, each face $\bt$ can be considered independent of each other face. Thus, this first instruction of the loop block is free from any control or data dependencies. The next line in the algorithm is a complex instruction, though, so it must be analyzed in parts.

The first part of the instruction on line~\ref{sbn3}, as denoted by the first three teal colored lines, is to read from face $\bt$ stored in static memory, the indices of the three points $\bp_a$, $\bp_b$, $\bp_c$. Because the face $\bt$ is independent, reading the indices of its three points is also free of dependencies. Next, $\bp_a$ is referenced in order to read the state of $\bN_a$ from volatile memory, as denoted as teal and coral colored lines, respectively. $\bN_a$ is stored in volatile memory, which may potentially be modified by other threads, because it is not known a priori which thread will discover the points which belong to that neighborhood, thus it must be accessible to any and all threads. Next, drawn in sand color, are the two union operations performed in succession on $\bN_a$ with the points $\bp_b$, then $\bp_c$. While these two operations are themselves independent, being performed only on values currently immutable by other procedures, they do rely on having already read the status of $\bN_a$, which indeed does have its own data dependence, hence the sand coloring. Finally illustrated as a double, coral colored arrow, the  the updated set $\bN_a$ is saved back into $\bN$ in volatile memory.

\tikzset{%
	>={Latex[width=2mm,length=2mm]},
	baseNode/.style = {rectangle, rounded corners,
		draw=black, fill=white, thick,
		minimum width=1cm, minimum height=1cm,
		text centered, font=\sffamily, inner sep=.2cm},
	baseLine/.style = {thick},%double},
	tealStyle/.style = {draw=MyTeal, fill=MyLtTeal},
	coralStyle/.style = {draw=MyCoral, fill=MyLtCoral},
	sandStyle/.style = {draw=MySand, fill=MyLtSand},
	%
	indNode/.style = {baseNode, tealStyle},
	indLine/.style = {baseLine, draw=MyTeal},
	depNode/.style = {baseNode, coralStyle},
	depLine/.style = {baseLine, draw=MyCoral},
	mixNode/.style = {baseNode, sandStyle},
	mixLine/.style = {baseLine, draw=MySand},
}
\begin{figure}[ht]
	\begin{tikzpicture}[node distance=0cm]
		\coordinate (center1) at (0cm,0cm);
		\node (sm) [indNode, xshift=-2.25cm] {$\bt$ in static memory};
		\node (vm) [depNode, anchor=west, xshift= 1.25cm] {$\bN$ in volatile memory};

		\coordinate (center2) at (0cm,-2cm);
		\node (pc) [indNode, left of=center2, xshift=-3.50cm] {$\bp_c$};
		\node (pb) [indNode, left of=center2, xshift=-2.25cm] {$\bp_b$};
		\node (pa) [indNode, left of=center2, xshift=-1.00cm] {$\bp_a$};

		\node (Na) [depNode, right of=center2, xshift=1.00cm, yshift=-.5cm] {$\bN_a$};

		\node (union1) at (0cm,-4cm) [mixNode] {$\bN_a \cup \{\bp_b\}$};

		\node (union2) at (0cm,-5.5cm) [mixNode] {$\bN_a \cup \{\bp_c\}$};

		%
		\draw[->, indLine] (sm) -- (pa);
		\draw[->, indLine] (sm) -- (pb);
		\draw[->, indLine] (sm) -- (pc);
		\draw[->, depLine] (vm.220) -- (Na);
		\draw[->, indLine] (pa.east) -- (Na.west);

		\draw[->, indLine] (pb.south) .. controls (-1.75cm,-3.5cm) .. (union1.west);
		\draw[->, mixLine] (Na) -- (union1.north);

		\draw[->, indLine] (pc.south) .. controls (-2cm,-5cm) .. (union2.west);
		\draw[->, mixLine] (union1) -- (union2);
		\draw[->, depLine, double] (union2.east) .. controls (2cm,-5cm) .. (vm);

	\end{tikzpicture}
	{\caption[Data Dependencies in Algorithm for Parallel Build Neighborhoods]{illustrates the data dependencies as found in Algorithm~\ref{alg:serialBuildNeighborhoods}. Operations with data dependencies are in coral color, independent operations are in teal color, and independent operations which reply on operations which have dependencies are in sand color.}\label{fig:paraBNDataDep}}
\end{figure}

Both reading from, and writing to $\bN_a$ in volatile memory constitutes a critical section in the algorithm, which must be accounted for in the design of the parallel variant. Furthermore, both dependencies lie in a single path of dependence, which means that the entire group of operations must be protected by a guarding mechanism as described in Section~\ref{ch2sPPssMS}. Fortunately, because both dependencies revolve around the same set $\bN_a$, a simple mutex per neighborhood will be sufficient. Lines~\ref{sbn4} and~\ref{sbn5} behave similarly to line~\ref{sbn3}, except they concern other neighborhoods, which in turn, need their own mutexes.\todoBackground{path of dependence} Fortunately, by exploiting the fact that the union operation is called exactly twice per each neighborhood for every face which contains its center point, by executing these two operations sequentially within a single mutex, one can mitigate exactly half of the possible collisions in the $\mathit{buildNeighborhoods}$ procedure.

Algorithm~\ref{alg:parallelBuildNeighborhoods} defines the structure and instructions required to implement a parallel variant of the serial procedure, $\mathit{buildNeighborhoods}$, and ensuring correctness by using a set of mutexes. The main function requires only the number of available processors $\rho$, the set of all triangular faces $\bT$, and the cardinality of the set of points $|\bP|$. First, the stride is calculated as the problem size with the unit of work being a single face $\bt$, divided by the number of available processors. Next, a set of mutexes is defined, containing the $|\bP|$ amount of mutexes to be used one each for each neighborhood. \todoReword{remove if no longer setting $\bM$} Then begins the loop to spawn a ``build'' thread for a quarter of the available processors in the system, with the scalar 4 being a result of each build thread's need to spawn 3 additional ``union'' threads. Finally, all the working threads must first synchronize before the family of sets $\bN$ can be realized.

Along with access to the set of triangular face $\bT|$ and set of mutexes $\bM$, each build thread in Algorithm~\ref{alg:parallelBuildNeighborhoods} also requires an index $\Pi$, which it uses along with the stride size $sigma$, to calculate the lower and upper boundaries, $\check{\sigma}$ and $\hat{\sigma}$, for the stride of the problem on which it should compute. Next, it iterates over each face $\bt$ within those stride boundaries, and spawns three union threads; one each for the three points comprising the corners of the current triangular face. Each union thread requires access to not only the family of sets of neighborhoods $\bN$ and the set of mutexes $\bM$, but also the index of the point which it will consider to be central, and two indices of the points which are neighboring it. With those inputs, each union thread then attempts to lock the mutex with the matching index of the central point, blocking until it is able to do so, in order to safely perform the union operation with the currently known neighborhood of the central point, and the set of its two newly discovered neighbors; finally, saving the updated neighborhood to shared memory, then unlocking the mutex.

\begin{algorithm}[ht]
	\DontPrintSemicolon
	\SetCommentSty{small}
	\SetKwFor{For}{for}{:}{}
	\SetKwProg{Func}{Function}{}{}
	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}

	\Input{the number of available processors $\rho$, \\
		the set of all triangular faces $\bT$, \\
		the cardinality of the set of points $|\bP|$}
	\Output{the family of sets of discovered neighborhoods $\bN$}

	\bigskip
\nl	\Func{parallelBuildNeighborhoods($\rho$, $\bT$, $|\bP|$)}{
\nl		$\sigma \leftarrow |\bT|\mathbin{/}\rho$\tcc*{assuming an integer quotient}
\nl		$\fM \leftarrow \{\mu_1,\,\ldots,\,\mu_{|\bP|}\}$\;
\nl		\For{$\Pi \leftarrow 1$ \KwTo $\rho\mathbin{/}4$}{
\nl			\ProgSty{$\sim$build($\Pi$, $\sigma$, $\fM$, $\bT$)}\;
		}

		\medskip
\nl		\ProgSty{synchronizeThreads()}\;
		\medskip
	}

	\bigskip
\nl	\Func{build($\Pi$, $\sigma$, $\fM$, $\bT$)}{
\nl		$\check{\sigma} \leftarrow (\Pi-1)\,\sigma+1$\tcc*{works through its stride}
\nl		$\hat{\sigma} \leftarrow \Pi\,\sigma$\;
\nl		\For(\tcc*[f]{$\bt = \left \{\bp_a, \bp_b, \bp_c\right \}$}){$\bt \in \{\bt_{\check{\sigma}},\ldots,\,\bt_{\hat{\sigma}}\}$}{
\nl			\ProgSty{$\sim$safeUnion($\fM$, $\bN$, $\bp_a$, $\bp_b$, $\bp_c$)}\;
\nl			\ProgSty{$\sim$safeUnion($\fM$, $\bN$, $\bp_b$, $\bp_a$, $\bp_c$)}\;
\nl			\ProgSty{$\sim$safeUnion($\fM$, $\bN$, $\bp_c$, $\bp_a$, $\bp_b$)}\;
		}
	}

	\bigskip
\nl	\Func{safeUnion($\fM$, $\bN$, $a$, $b$, $c$)}{
\nl		$\ProcSty{lock}(\mu_a)$\;
\nl		$\bN_a \leftarrow \bN_a \cup \{b,\,c\}$\;
\nl		$\ProcSty{unlock}(\mu_a)$\;
	}
	\caption{Parallel algorithm for building the family of sets of all members of each neighborhood discovered in the mesh \label{alg:parallelBuildNeighborhoods}}
\end{algorithm}%
\nomenclature[]{$\rho$}{the number of available processors}%
\nomenclature[]{$\sigma$}{the ``stride'', the size of a block of work intended for a single processor, equal to the problem size divided by the number of available processors}%
\nomenclature[]{$\check{\sigma}$}{the index of the beginning of a stride}%
\nomenclature[]{$\hat{\sigma}$}{the index of the beginning of a stride}%
\nomenclature[]{$\Pi$}{a process, to be executed}%
\nomenclature[]{$\fM$}{a set of mutexes}%
\nomenclature[]{$\mu_v$}{a specific mutex}%
\nomenclature[]{$\sim process()$}{a process to be run in a new thread}%
\todoAsk{use KwTo or \{...\}?}
\todoAsk{remove the "main" function in each algorithm (except the 5)?}
\todoAsk{define $\bM$, set it as an input, or just use it?}

The motivation for Algorithm~\ref{alg:parallelRecursiveCensusNeighborhoods} is that a total count of all neighbors in all neighborhoods $\hat{n}$, should be provided so that the work load incurred by loops found in the next two parts of \forf{t} algorithm, which iterate over each neighbor in the family of sets $\bN$, can be predicted and evenly delegated to each independent thread of execution. While a running sum of cardinalities could be implemented within Algorithm~\ref{alg:parallelBuildNeighborhoods}, unlike in the serial version, it would very inefficient due to the added overhead of collisions with the guarding mechanism required to protect the total sum.  Algorithm~\ref{alg:parallelRecursiveCensusNeighborhoods} only requires as inputs a pre-built family of sets of neighborhoods $\bN$, and the number of processors available in the system, but is highly parallel and performs at a rate of $O(log_2(n))$,\todoReword{not sure how to word bigOrate} so when using a system with multiple processors, it is a much or efficient alternative to calculating the sum implicitly while building $\bN$.

As Algorithm~\ref{alg:parallelRecursiveCensusNeighborhoods} is a recursive algorithm, it can be described by splitting it into three distinct parts. The first part, ``the termination clause'', is defined as when the cardinality of the current subset of $\bN$ is only two, evaluate the sum of each member $\bN_i$, then return the sum of all the results. Not that this ignores the trivial edge case of families of sets with a very small cardinality of less than three. In all other cases, when the cardinality of the current subset of $\bN$ is greater than two, the second part, ``working towards the termination state'', begins. The second part of this recursive strategy describes summing in parallel, the cardinality or value of each adjacent pair of members in the current subset of $\bN$, then saving the sum of each addition in a new ordered subset of integers $\widetilde{\bN}$, which will have half the cardinality of the current subset. In the third and final part, ``the recursive call'', the function \textit{parallelRecursiveCensusNeighborhoods} calls itself using the new subset $\widetilde{\bN}$ as a parameter instead of the original $\bN$.
\todoReword{big O remark at end is too sudden}
\todoBackground{recursive algorithms, three parts}

\begin{algorithm}[ht]
	\DontPrintSemicolon
	\SetCommentSty{small}
	\SetKwFor{For}{for}{:}{}
	\SetKwProg{Func}{Function}{}{}
	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}

	\Input{the number of available processors $\rho$, \\
		the family of sets of neighborhoods $\bN$}
	\Output{the count of all neighbors in all neighborhoods $\hat{n}$}

	\bigskip
\nl	\Func{parallelRecursiveCensusNeighborhoods($\rho$, $\bN$)}{
\nl		\eIf{$|\bN| \leq 2$}{
\nl			$\hat{n} \leftarrow \sum_{i=1}^{|\bN|}\bN_i$\;%\underset{i=1}{\overset{|\bN|}{\sum}}|\bN_i|$\;
		}{%Else
\nl			$\sigma \leftarrow |\bN|\mathbin{/}(2\,\rho)$\;
\nl			\For{$\Pi \in \{1,\ldots,\rho\}$}{
\nl				\ProgSty{$\sim$parallelSum($\Pi$, $\sigma$, $\bN$)}\;
			}
			\medskip
\nl			\ProgSty{synchronizeThreads()}\;
			\medskip
\nl			\ProgSty{parallelRecursiveCensusNeighborhoods($\rho$, $\widetilde{\bN}$)}\;
		}
	}

	\bigskip
\nl	\Func{parallelSum($\Pi$, $\sigma$, $\bN$)}{
\nl		$\check{\sigma} \leftarrow (\Pi-1)\,\sigma+1$\;
\nl		$\hat{\sigma} \leftarrow 2\,\Pi\,\sigma$\;
\nl		\For{$v \in \{\check{\sigma},\,\check{\sigma}\sps{}2,\,\check{\sigma}\sps{}4,\ldots,\,\hat{\sigma}\}$}{
\nl			\eIf(\tcc*[f]{only occurs in first call}){$\bN$ is a family of sets}{\label{algPRCNbNdistinction}
\nl				$\widetilde{\bN_v} \leftarrow |\bN_v| + |\bN_{\sxpx{v}{1}}|$\;
			}{%else
\nl				$\widetilde{\bN_v} \leftarrow \bN_v + \bN_{\sxpx{v}{1}}$\;
			}
		}
	}
	\caption{Parallel algorithm for recursively counting a census of all neighbors in all neighborhoods \label{alg:parallelRecursiveCensusNeighborhoods}}
\end{algorithm}%
\nomenclature[]{$\hat{n}$}{a census, the count of all neighbors in all neighborhoods}%
\nomenclature[]{$\widetilde{\bN}$}{a subset of $\bN$ used temporarily in Algorithm~\ref{alg:parallelRecursiveCensusNeighborhoods}}%
\todoReword{mention that non-existent neighborhoods should be treated as having a cardinality of 0}

It is important to notice in line~\ref{algPRCNbNdistinction}, the distinction between the family of sets $\bN$ in the first call of \textit{parallelRecursiveCensusNeighborhoods}, with that of the set of integers accumulating in the subset $\widetilde{\bN}$ in subsequent calls.

%
%
\subsection{Calculating Edge Lengths}
\label{ch5sPAssCEL}
Next, we examine the serial Algorithm~\ref{alg:serialCalculateEdgeLengths}, which has the goal of building a set of pre-calculated edge lengths $\bE$, as well as determining the global minimum edge length $\gelm$; both essential parameters of  Algorithm~\ref{alg:serialConvolveFilter}. Already in line~\ref{scel1}, we encounter a loop over each point $\bp_v$ in $\bP$. In order to determine if the iterations of the loop may instead be computed in parallel, an analysis of every operation in the loop block is required, which in this case, includes lines~\ref{scel2}-~\ref{scel5}. The first internal line,~\ref{scel2}, starts another loop over each point $\bp_i$ in $\bN_v$. \todoReword{why important to know ?} As we have seen very clearly in Figure~\ref{fig:neighborhoods}, the cardinality of each individual neighborhood can not be predicted for irregular, triangle meshes, like those typical of acquired \tdd{}. However, that becomes less important because it is possible to know the total count of neighbors of in all neighborhoods $\hat{n}$, by counting the size of each neighborhood a posteriori, as is done in Algorithm~\ref{alg:parallelRecursiveCensusNeighborhoods}. With $\hat{n}$, we may unroll this pair of loops and instruct a calculable number of threads to process the loop block in parallel. If the average number of neighbors per point is six\todoResearch{average number of neighbors}, then the number of edge lengths to be calculated and stored will be six times as large as the cardinality of $\bP$.

Line~\ref{scel3} of Algorithm~\ref{alg:serialCalculateEdgeLengths} is the $\ellstar$ operation, the most costly operation performed by \forf{t}, due to use of the $\sqrt{(\cdot)}$ operation. Therefore, unlike with the union operation in Algorithm~\ref{alg:parallelBuildNeighborhoods}, it is of paramount importantance that we avoid any unnecessary duplication of the $\ellstar$ operation. In Algorithm~\ref{alg:serialBuildNeighborhoods}, each pair of adjacent points are represented twice, being indexed once from both directions, and while calculating the length both times is exactly what we want to avoid, it is a design choice related to Section\todoReference{memory vs speed}\todoBackground{memory vs speed} whether to store the length twice. The benefit of storing the set of adjacent points in this way, it that it creates an implicit reverse lookup-table which is well documented\todoCitation{multiples, reverse lookup table} for increasing the speed of computations, and further simplifies the complexity of indexing the values, conversely to save memory, one could store the value only once by implementing the control structures for detecting if an edge length has already been saved \todoReference{more details about this method in future work}, then when retrieving the values, one could search for the edge length required at the cost of compute time. We have chosen to detail the first, speedier method.

Algorithm~\ref{alg:parallelCalculateEdgeLengths} is the parallel algorithm for calculating all the edge lengths between each pair of adjacent points in the mesh. It requires the knowledge of and access to the number of available processors in the system $\rho$, the set of all points $\bP$, the family of sets of discovered neighborhoods $\bN$, the average size of every neighborhood in $\bar{n}$, and the count of all neighbors in all neighborhoods $\hat{n}$, and produces as an output, the set of pre-calculated edge lengths $\bE$, and the globally shortest edge length $\gelm$; both instrumental to the calculation of $\Forf{t}$. This algorithm has been split further into three subroutines in order to maximize efficiency by facilitating the balance of work loaded in parallel onto each processor.

\begin{algorithm}[ht]
	\DontPrintSemicolon
	\SetCommentSty{small}
	\SetKwFor{For}{for}{:}{}
	\SetKwProg{Func}{Function}{}{}
	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}

	\Input{the number of available processors $\rho$, \\
		the set of all points $\bP$, \\
		the family of sets of discovered neighborhoods $\bN$, \\
		the average size of every neighborhood in $\bar{n}$, \\
		the count of all neighbors in all neighborhoods $\hat{n}$}
	\Output{the set of pre-calculated edge lengths $\bE$, \\
		the globally shortest edge length $\gelm$}

	\bigskip
\nl	\Func{parallelCalculateEdgeLengths($\rho$, $\bP$,\,$\bN$,\,$\hat{n}$)}{
\nl		$\sigma \leftarrow \hat{n}\mathbin{/}\rho$\label{algPCELellstar}\;
\nl		\For{$\Pi \in \{1,\,\ldots,\,\left \lceil\rho/\bar{n}\right\rceil\}$}{
\nl			\ProgSty{$\sim$calculateLengths($\Pi$, $\sigma$, $\mu$, $\bP$,\,$\bN$)}\;
		}

		\medskip
\nl		\ProgSty{synchronizeThreads()}\;
		\medskip
	}

	\bigskip
\nl	\Func{calculateLengths($\Pi$, $\sigma$, $\mu$, $\bP$,\,$\bN$)}{
\nl		$\check{\sigma} \leftarrow (\Pi-1)\,\sigma+1$\;
\nl		$\hat{\sigma} \leftarrow \Pi\,\sigma$\;
\nl		\For{$\bp_v \in \{\bp_{\check{\sigma}},\ldots,\,\bp_{\hat{\sigma}}\}$}{
\nl			\For{$\bp_i \in \bN_v$}{
\nl				\ProgSty{$\sim$safeEdgeLengthCalculation($\mu$, $\bE$, $\gelm$, $\bp_v$, $\bp_i$)}\;
			}
		}
	}

	\bigskip
\nl	\Func{safeEdgeLengthCalculation($\mu$, $\bE$, $\gelm$, $\bp_v$, $\bp_i$)}{
\nl		$\bE_{\sv{i}} \leftarrow |\bp_i - \bp_v|$\tcc*[r]{$\ellstar$, Eq:~\ref{eq:localMinimumEdgeLength}}
\nl		\If(\tcc*[f]{heuristic only\footnotemark}){$\bE_{\sv{i}} < \gelm$}{\label{algPCELhcs}
\nl			$\ProcSty{lock}(\mu)$\;
\nl			$\gelm \leftarrow \min\left \{\gelm,\,\bE_{\sv{i}}\right \}$\label{algPCELgelm}\tcc*[r]{Eq:~\ref{eq:globalMinimumEdgeLength}}
\nl			$\ProcSty{unlock}(\mu)$\;
		}
	}
	\caption{Parallel algorithm for calculating all the edge lengths between each pair of adjacent points in the mesh\label{alg:parallelCalculateEdgeLengths}}
\end{algorithm}
\footnotetext{While it is true that we are attempting to avoid any unnecessary edge length calculations or mutex locks, the hidden message in this line is honestly just a happy accident.}
\todoBackground{lock/unlock/mutex}
\todoReword{$\bE_{\sv{i}}$ is a unique address, so no mutex required}
\todoBackground{future work, can calculate average neighborhood size in alg.1 or 4} 

The initial function, \textit{parallelCalculateEdgeLengths}, requires all of the inputs listed in the previous paragraph, then calculates the stride with the problem size equating to the count of all neighbors in all neighborhoods $\hat{n}$. Next, the set of mutexes is prepared, and the loop iterating over a portion of the count of processors is encountered, calling the \textit{calculateLengths} function in each iteration. Because each thread will be expected to spawn an additional thread for each pair of adjacent points found in every neighborhood in its designated stride of the work load, the greater portion of processors, scaled to the average neighborhood size of the mesh $\bar{n}$, is held in reserve for those spawned threads to be able to run in parallel. Finally, all the working threads must synchronized before the set of pre-calculated edge lengths $\bE$ before the final value of $\gelm$ may be used.

The \textit{calculateLengths} function requires an index $\Pi$, which it uses along with the stride size $sigma$, to calculate the lower and upper boundaries, $\check{\sigma}$ and $\hat{\sigma}$, for the stride of the total problem which it should compute. Next, the function iterates over each point $\bp_v$ within its stride boundaries, as well as each neighbor $\bp_i$ in the current center point's neighborhood $\bN_v$, spawning new threads to execute instances of the \textit{safeEdgeLengthCalculation} procedure in each iteration.

The \textit{safeEdgeLengthCalculation} function requires access to the set of edge lengths $\bE$ being collaboratively populated by each other instance of itself, as well as the single mutex $mu$ used to guard the final reading of and writing to the shared value of $\gelm$. Naturally, also required are the coordinates of the two points, between which the distance is being calculated. In line~\ref{algPCELellstar}, the first line of the function, the L2-norm of the difference between the two points is already calculated; this is the $\ellstar$ operation. There are two race conditions in line~\ref{algPCELgelm} which must be avoided, however it would be incredibly inefficient to have all $(\bar{n}-\rho)\mathbin{/}\bar{n}$ threads attempt to lock the same, single mutex $\mu$. The solution is the heuristic conditional statement in line~\ref{algPCELhcs}, testing the worthiness of incurring the cost of attempting to lock the shared mutex guarding the reads and writes to $\gelm$. We call this conditional statement heuristic, in order to call attention to the fact that it may give an inaccurate result due to race conditions between the threads operating in parallel. \todoResearch{just how much time can be saved with this heuristic?}

In the next section, we will see how the pre-calculations of... %Algorithms~\ref{}

%
%
\subsection{Convolving the Filter}
\label{ch5sPAssCF}

Subsection Intro...\todoReword{elaborate}
the stride is calculated from 1 thread for each disc accumulation + a thread each for sector of every neighborhood.

\begin{algorithm}[ht]
	\DontPrintSemicolon
	\SetCommentSty{small}
	\SetKwFor{For}{for}{:}{}
	\SetKwProg{Func}{Function}{}{}
	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}

	\Input{the number of available processors $\rho$, \\
		the set of all points $\bP$, \\
		the family of sets of discovered neighborhoods $\bN$, \\
		the count of all neighbors in all neighborhoods $\hat{n}$, \\
		the set of pre-calculated edge lengths $\bE$, \\
		the globally shortest edge length $\gelm$, \\
		the set of function values $\bF$. \\
		the chosen number of iterations $\tau$}
	\Output{the set of one-ring weighted mean function values $\bF'$}

	\bigskip
	\linespread{1}\selectfont
\nl	\Func{parallelConvolveFilter($\rho$, $\bP$, $\bN$, $\hat{n}$, $\bE$, $\gelm$, $\bF$, $\tau$)}{
\nl		\For{$\tau\leftarrow 1\;\KwTo\;\#iterations$}{
\nl			$\sigma \leftarrow (|\bP|+\hat{n})\mathbin{/}\rho$\;
\nl			$\fM \leftarrow \{\mu_1,\dots,\mu_{|\bP|}\}$\;
\nl			\For{$\Pi \in \{1,\ldots,\rho\}$}{
\nl				\ProgSty{$\sim$safeAccumulatesGeoDiscMean($\Pi$, $\sigma$, $\fM$, $\bP$, $\bN$, $\bE$, $\gelm$, $\bF$)}\;
			}
\nl			\ProgSty{synchronizeThreads()}\;
			\medskip
			\nl	$\bF' \leftarrow \left \{f'_1,\ldots,\,f'_{|\bP|}\right \}$\;
			\nl $\bF \leftarrow \bF'$\tcc*{smooth newest values every iteration}
		}
	}

	\bigskip
\nl	\Func{safeAccumulatesGeoDiscMean($\Pi$, $\sigma$, $\fM$, $\bP$, $\bN$, $\bE$, $\gelm$, $\bF$)}{
\nl		$\check{\sigma} \leftarrow (\Pi-1)\,\sigma+1$\;
\nl		$\hat{\sigma} \leftarrow \Pi\,\sigma$\;
\nl		$\widetilde{\fM} \leftarrow \left \{\tilde{\mu}_{1},\dots,\tilde{\mu}_{\hat{n}}\right \}$\;
\nl		\For(\tcc*[f]{together, these}){$\bp_v \in \{\bp_{\check{\sigma}},\ldots,\,\bp_{\hat{\sigma}}\}$}{
\nl			\For(\tcc*[f]{loops equal $\hat{n}$}){$\bp_i \in \bN_v$}{
				\smallskip
				\ProgSty{$\sim$safeAccumulateSectorMean($\widetilde{\fM}$, $\bE$, $\gelm$, $\bp_v$, $\bp_i$, $\bF$, $\tilde{f}_v$, $\tilde{A}_v$)}\;
			}
\nl			\ProgSty{synchronizeThreads(\{$\check{\sigma}$, \ldots, $\hat{\sigma}$\})}\;

			\medskip
\nl			$\ProcSty{lock}(\mu_v)$\;
\nl			$f'_v \leftarrow \tilde{f}_v\mathbin{/}\tilde{A}_v$\tcc*[r]{Eq:~\ref{eq:meanFuncValAtPv}}
\nl			$\ProcSty{unlock}(\mu_v)$\;
		}
	}

%	\bigskip
%	\emph{...continued.}\;
%	\caption{Parallel algorithm for convolving \Forf{t} (Part 1 of 2)\label{alg:parallelConvolveFilter1}}
%\end{algorithm}%

%\begin{algorithm}[ht]
%	\DontPrintSemicolon
%	\SetCommentSty{small}
%	\SetKwFor{For}{for}{:}{}
%	\SetKwProg{Func}{Function}{}{}
%	\setcounter{AlgoLine}{66}

%	\emph{...continued.}\;

	\bigskip
\nl	\Func{safeAccumulateSectorMean($\widetilde{\fM}$, $\bE$, $\gelm$, $\bp_v$, $\bp_i$, $\bF$, $\tilde{f}_v$, $\tilde{A}_v$)}{
		\linespread{1.5}\selectfont
\nl		$\kern-0.5pt\alpha \leftarrow cos^{-1}$
		\begin{Large}
			$\kern-6pt\left (\frac{\bE_c^2\,+\,\bE_b^2\,-\,\bE_a^2}{2\,\cdot\,\bE_c\,\cdot\,\bE_b}\right )$\tcc*[r]{Eq:~\ref{eq:alphaFromEdgeLengths}}
		\end{Large}
		\linespread{1.2}\selectfont
\nl		$\kern0.00pt\beta \leftarrow (\pi - \alpha)\mathbin{/}2$\tcc*[r]{Eq:~\ref{eq:betaFromHalfAlpha}}
\nl		$\kern-1.5ptA \leftarrow \Big(\gelm\,\Big)^2\kern-4pt\cdot\alpha\mathbin{/}2$\tcc*[r]{Eq:~\ref{eq:circularSectorArea}}
\nl		$\kern1.00pt\check{\ell} \leftarrow \big(4\cdot\gelm\cdot\sin(\alpha\mathbin{/}2)\big)\mathbin{/}3\,\alpha$\tcc*[r]{Eq:~\ref{eq:distToCoG}}
\nl		$\kern1.00pt\zeta \leftarrow \gelm\mathbin{/}\sin(\beta)$\tcc*[r]{Eq:~\ref{eq:zeta}}
\nl		\For{$j \in {1,2}$}{
\nl			$\tilde{\ell}_j \leftarrow \zeta\mathbin{/}\bE_j$\tcc*[r]{Eq:~\ref{eq:distanceIForInterpolation},~\ref{eq:distanceIp1ForInterpolation}}
\nl			$f'_j \leftarrow f_0\cdot(1 - \tilde{\ell}_j) + f_j\cdot\tilde{\ell}_j$\tcc*[r]{Eq:~\ref{eq:interpolatedFi},~\ref{eq:interpolatedFip1}}
		}
\nl		$\check{f} \leftarrow f_0\cdot(1 - \check{\ell}) + \big((f'_1 + f'_2)\cdot\check{\ell}\big)\mathbin{/}2$\tcc*[r]{Eq:~\ref{eq:weightedMeanAtCoGatSector}}
		\linespread{1.0}\selectfont
\nl		$\ProcSty{lock}(\tilde{\mu}_{\sv{i}})$\;
\nl		$\kern2.0pt\tilde{f}_v \leftarrow \tilde{f}_v + A\cdot\check{f}$\tcc*[r]{Eq:~\ref{eq:meanFuncValAtPv}}
\nl		$\kern0.0pt\tilde{A}_v \leftarrow \tilde{A}_v + A$\tcc*[r]{Eq:~\ref{eq:meanFuncValAtPv}}
\nl		$\ProcSty{lock}(\tilde{\mu}_{\sv{i}})$\;
	}

	\caption{Parallel algorithm for convolving \Forf{t} (Part 2 of 2)\label{alg:parallelConvolveFilter}}
\end{algorithm}%
\nomenclature[]{$\widetilde{\fM}$}{a smaller set of mutexes, for a particular neighborhood}%
\nomenclature[]{$\tilde{\mu}_{\sv{i}}$}{a member of }%
%\todoReword{ensure counter is real value}
\todoReword{make sure sigmas include control htereads too}
\todoReword{Alg3,6 output}

%
%
%
%
%\section[Acceleration by GPGPU]{Acceleration by General-purpose
%computing on Graphics Processing Units (GPGPU)}

%
%Data Partitioning:
%Calculations depend on specific data structures.~\cite[p.~357]{Lang17}
%As in edge lengths depend on the neighborhoods.

%
%Data Dependencies: ~\cite[p.~358]{Lang17}
%Section~\ref{ch2sACssCVP}
%
%Functional Partitioning: ~\cite[p.~359]{Lang17}
%different operations on the same data
\ldots

%
%
%
\section{Summary}
\ldots
%then calculate all the edge lengths $\ell_{vk}$, as well as the global minimum edge length $\gelm$. Afterwards, one may efficiently convolve the filter, for as many number of iterations as required to achieve the desired smoothing effect.

